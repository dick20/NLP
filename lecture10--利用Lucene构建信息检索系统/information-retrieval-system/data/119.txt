信息论是运用概率论与数理统计的方法研究信息、信息熵、通信系统、数据传输、密码学、数据压缩等问题的应用数学学科。信息系统就是广义的通信系统，泛指某种信息从一处传送到另一处所需的全部设备所构成的系统。信息论是关于信息的理论，应有自己明确的研究对象和适用范围。但从信息论诞生的那时起人们就对它有不同的理解。
信息论将信息的传递作为一种统计现象来考虑，给出了估算通信信道容量的方法。信息传输和信息压缩是信息论研究中的两大领域。这两个方面又由信息传输定理、信源－信道隔离定理相互联系。
香农被称为是“信息论之父”。人们通常将香农于1948年10月发表于《贝尔系统技术学报》上的论文《A Mathematical Theory of Communication》（通信的数学理论）作为现代信息论研究的开端。这一文章部分基于哈里·奈奎斯特和拉尔夫·哈特利先前的成果。在该文中，香农给出了信息熵（以下简称为“熵”）的定义：

这一定义可以用来推算传递经二进制编码后的原信息所需的信道带宽。熵度量的是消息中所含的信息量，其中去除了由消息的固有结构所决定的部分，比如，语言结构的冗余性以及语言中字母、词的使用频度等统计特性。
信息论中熵的概念与物理学中的热力学熵有着紧密的联系。玻耳兹曼与吉布斯在统计物理学中对熵做了很多的工作。信息论中的熵也正是受之启发。
互信息(Mutual Information)是另一有用的信息度量，它是指两个事件集合之间的相关性。两个事件X和Y的互信息定义为：

其中

是联合熵(Joint Entropy)，其定义为：

互信息与多元对数似然比检验以及皮尔森χ2校验有着密切的联系。
信息论是20世纪40年代后期从长期通讯实践中总结出来的一门学科，是专门研究信息的有效处理和可靠传输的一般规律的科学。
切略（E.C.Cherry）曾写过一篇早期信息理论史，他从石刻象形文字起，经过中世纪启蒙语言学，直到16世纪吉尔伯特（E.N.Gilbert）等人在电报学方面的工作。
20世纪20年代奈奎斯特（H.Nyquist）和哈特莱（L.V.R.Hartley）最早研究了通信系统传输信息的能力，并试图度量系统的信道容量。现代信息论开始出现。
1948年克劳德·香农（Claude Shannon）发表的论文“通信的数学理论”是世界上首次将通讯过程建立了数学模型的论文，这篇论文和1949年发表的另一篇论文一起奠定了现代信息论的基础。
由于现代通讯技术飞速发展和其他学科的交叉渗透，信息论的研究已经从香农当年仅限于通信系统的数学理论的狭义范围扩展开来，而成为现在称之为信息科学的庞大体系。
传统的通信系统如电报、电话、邮递分别是传送电文信息、语声信息和文字信息的；而广播、遥测、遥感和遥控等系统也是传送各种信息的，只是信息类型不同，所以也属于信息系统。有时，信息必须进行双向传送，例如电话通信要求双向交谈，遥控系统要求传送控制用信息和反向的测量信息等。这类双向信息系统实际上是由两个信息系统构成。所有信息系统都可归纳成如图所示的模型来研究它的基本规律。
信源：信息的源泉或产生待传送的信息的实体，如电话系统中的讲话者，对于电信系统还应包括话筒，它输出的电信号作为含有信息的载体。
信宿：信息的归宿或接受者，在电话系统中这就是听者和耳机，后者把接收到的电信号转换成声音，供听者提取所需的信息。
信道：传送信息的通道，如电话通信中包括中继 器在内的同轴电缆系统，卫星通信中地球站的收发信机、天线和卫星上的转发器等。
编码器：在信息论中是泛指所有变换信号的设备，实际上就是终端机的发送部分。它包括从信源到信道的所有设备，如量化器、压缩编码器、调制器等，使信源输出的信号转换成适于信道传送的信号。
译码器：是编码器的逆变换设备，把信道上送来的信号转换成信宿能接受的信号，可包括解调器、译码器、数模转换器等。
当信源和信宿已给定、信道也已选定后，决定信息系统性能就在于编码器和译码器。设计一个信息系统时，除了选择信道和设计其附属设施外，主要工作也就是设计编译码器。一般情况下，信息系统的主要性能指标是它的有效性和可靠性。有效性就是在系统中传送尽可能多的信息；而可靠性是要求信宿收到的信息尽可能地与信源发出的信息一致，或者说失真尽可能小。最佳编译码器就是要使系统最有效和最可靠。但是，可靠性和有效性往往是相互矛盾的。越有效常导致不可靠，反之也是如此。从定量意义上说，应使系统在规定的失真或基本无失真的条件下，传送最大的信息率；或者在规定信息率的条件下，失真最小。计算这最大信息率并证明达到或接近这一值的编译码器是存在的，就是信息论的基本任务。只讨论这样问题的理论可称为仙农信息论般认为信息论的内容尚应更广泛一些，即包括提取信息和保证信息安全的理论。后者就是估计理论、检测理论和密码学。
信息论是建立在概率论基础上而形成的，也就是从信源符号和信道噪声的概率特性出发的。这类信息通常称为语法信息。其实，信息系统的基本规律也应包括语义信息和语用信息。语法信息是信源输出符号的构造或其客观特性所表现与信宿的主观要求无关，而语义则应考虑各符号的意义，同样一种意义，可用不同语言或文字来表示，各种语言所包含的语法信息可以是不同的。一般地说，语义信息率可小于语法信息率；电报的信息率可低于表达同一含义的语声的信息率就是一个例子。更进一步，信宿或信息的接受者往往只需要对他有用的信息，他听不懂的语言是有意义的，但对他是无用的。所以语用信息，即对信宿有用的信息一般又小于语义信息。倘若只要求信息系统传送语义信息或语用信息，效率显然会更高一些。在目前情况下，关于语法信息，已在概率论的基础上建立了系统化的理论，形成一个学科；而语义和语用信息尚不够成熟。因此，关于后者的论述通常称为信息科学或广义信息论，不属于一般信息论的范畴。概括起来，信息系统的基本规律应包括信息的度量、信源特性和信源编码、信道特性和信道编码、检测理论、估计理论以及密码学。
编码学
密码学与密码分析学
数据传输
数据压缩
检测理论
估计理论
政治学（政治沟通）
信息论是一门用数理统计方法来研究信息的度量、传递和变换规律的科学。它主要是研究通讯和控制系统中普遍存在着信息传递的共同规律以及研究最佳解决信息的获限、度量、变换、储存和传递等问题的基础理论。
信息论的研究范围极为广阔。一般把信息论分成三种不同类型：
(1)狭义信息论是一门应用数理统计方法来研究信息处理和信息传递的科学。它研究存在于通讯和控制系统中普遍存在着的信息传递的共同规律，以及如何提高各信息传输系统的有效性和可靠性的一门通讯理论。
(2)一般信息论主要是研究通讯问题，但还包括噪声理论、信号滤波与预测、调制与信息处理等问题。
(3)广义信息论不仅包括狭义信息论和一般信息论的问题，而且还包括所有与信息有关的领域，如心理学、语言学、神经心理学、语义学等。
信息是确定性的增加----逆Shannon信息定义；
信息是物质、能量、信息的标示----Wiener信息定义的逆;
信息是事物及其属性标识的集合。
信息就是一种消息，它与通讯问题密切相关。1948年贝尔研究所的香农在题为《通讯的数学理论》的论文中系统地提出了关于信息的论述，创立了信息论。维纳提出的关于度量信息量的数学公式开辟了信息论的广泛应用前景。1951年美国无线电工程学会承认信息论这门学科，此后得到迅速发展。20世纪50年代是信息论向各门学科冲击的时期，60年代信息论不是重大的创新时期，而是一个消化、理解的时期，是在已有的基础上进行重大建设的时期。研究重点是信息和信源编码问题。到70年代，由于数字计算机的广泛应用，通讯系统的能力也有很大提高，如何更有效地利用和处理信息，成为日益迫切的问题。人们越来越认识到信息的重要性，认识到信息可以作为与材料和能源一样的资源而加以充分利用和共享。信息的概念和方法已广泛渗透到各个科学领域，它迫切要求突破申农信息论的狭隘范围，以便使它能成为人类各种活动中所碰到的信息问题的基础理论，从而推动其他许多新兴学科进一步发展。人们已把早先建立的有关信息的规律与理论广泛应用于物理学、化学、生物学等学科中去。一门研究信息的产生、获取、变换、传输、存储、处理、显示、识别和利用的信息科学正在形成。
信息科学是人们在对信息的认识与利用不断扩大的过程中，在信息论、电子学、计算机科学、人工智能、系统工程学、自动化技术等多学科基础上发展起来的一门边缘性新学科。它的任务主要是研究信息的性质，研究机器、生物和人类关于各种信息的获取、变换、传输、处理、利用和控制的一般规律，设计和研制各种信息机器和控制设备，实现操作自动化，以便尽可能地把人脑从自然力的束缚下解放出来，提高人类认识世界和改造世界的能力。信息科学在安全问题的研究中也有着重要应用。
Materialism
物质、能量与信息是组成世界的三大要素。人们已经很深入地了解了物质与能量，而对信息的认识才刚起步。那么，信息是什么？它又是以何种方式存在的？它有着怎样的作用？以下是我的猜想，希望对人类进一步认识世界有一定帮助。
一、信息的定义
非世界三要素的信息定义:信息是事物及其属性标识的集合。不含世界三要素的的信息定义.
含三要素的信息定义：
1．信息是确定性的增加----逆Shannon信息定义；
2．信息就是信息，信息是物质、能量、信息及其属性的标示----Wiener信息定义的逆.
信息（information）是客观事物状态和运动特征的一种普遍形式，客观世界中大量地存在、产生和传递着以这些方式表示出来的各种各样的信息。然而，这只是对于我们所生活的三维空间而言的，信息还有更深藏的本质。那么，难道信息还存在于四维空间（这里所说的四维空间不包括时间，而是空间的四维状态）中吗？是的，但要明确一点，信息只存在于四维空间，三维空间中的信息只是四维空间中真实信息的影子。信息大量存在于四维空间中，其本质是在四维空间中存在的一种信息子（informer，假想的存在于四维空间的组成信息的基本单位）的规则排布。
信息是事件（corritor）发生的根本原因，这将在第三节中细作分析。
二、信息的性质
信息有以下性质：客观性、广泛性、完整性、专一性。首先，信息是客观存在的，它不是由意志所决定的，但它与人类思想有着必然联系（第四节将具体分析）。同时，信息又是广泛存在的，四维空间被大量信息子所充斥。信息的一个重要性质是完整性，每个信息子不能决定任何事件，须有两个或两个以上的信息子规则排布为完整的信息，其释放的能量才足以使确定事件发生。信息还有专一性，每个信息决定一个确定事件，但相似事件的信息也有相似之处，其原因的解释需要信息子种类与排布密码理论的进一步发现。
三、信息论机制
在平常状态下，信息子杂乱无章地分布于四维空间中。当三维空间中的分子摩擦碰撞时，其中的能量逃逸到四维空间中，启动了信息子的规则排布，排布好的信息子又将能量释放出来，进入三维空间，引起其他分子的摩擦碰撞，如此循环下去。如果被引起摩擦碰撞的分子恰好是决子（decider，决定事件的因子，如引起神经冲动的钠钾离子、引起雷电的电荷），并且有一定物质的量的决子被引起摩擦碰撞时，事件发生。当然，不同分子摩擦碰撞产生的能量不同，其引起的信息子的排布形式的种类也不同，因而决定的事件也不同。
然而，在宇宙爆炸前只有信息存在，一个决定因素（现在还不了解这个因素是什么）导致了信息子的偶然规则排布，一部分信息子转化为能量（信息子转化为能量是有一定条件的，这只有在宇宙爆炸前或初期才能实现），能量再在一定条件下转化为物质，并继续转移转化，最终形成了我们现在的宇宙。因此，信息子的有序排布是事件发生的根本原因，物质摩擦碰撞是事件发生的直接原因，而能量的传递是事件发生的必要条件。
四、信息论假说的实例
1．思想与记忆：思想是我们一直捉摸不透的东西，而按照信息论假说来讲，思想其实就是一种信息。大脑中的某些特定分子摩擦碰撞，引起了某些信息子的规则排布，在三维空间中的表现就是产生电流，引起脑细胞的活动，这便是思想的本质，当然，不同信息表现出不同思想。然而，这不等于我们的思想是早已限定好了的吗？其实就是这样。只不过我们脑中分子数量是庞大的，其能引起信息子的排布形式的种类是极其多的，我们的思想不过也只开发了很少一部分。现实中我们所谓的思想还要有另一个因素，那就是需要通过一个完整复杂的调节机制将其表达出来，这个调节机制对于人类来说便是神经系统，因此只有我们能将复杂的思想表达出来。记忆是思想的特化，是信息引起摩擦碰撞的分子恰好是以前产生思想的分子（记忆的决子）时，以前的思想便会再次通过特定信息子的规则排布表达出来。这样看来，我们的思想是连续的，前一刻的思想直接决定了后一刻的思想，只是我们并没发觉也没有手段去发现罢了。
2．生命现象：人的生老病死也可以通过信息论假说来解释。人生病其实是不融合分子（细菌或病毒）与体内分子摩擦引起的信息。成长其实是各种各样的外界分子（如钙离子）进入人体内与体内分子摩擦引起的信息。衰老与死亡是细胞内分子摩擦引起的信息，其宏观表现为细胞的衰老与凋亡，进而影响人。
3．预感与巧合：预感是思想的一种极特殊的形式，当脑中某些分子摩擦引起信息子排布后，信息并未释放全部能量，而是只将其中一部分能量先释放出来，引起预感决子的摩擦，剩下的能量则在另外的时刻释放出来，并由于与前一部分能量同源，恰好引起事件决子的摩擦，从而印证了预感。巧合也是一种极特殊的现象，其本质是信息释放的能量分为两半进入到三维空间中的不同地点，引发相同分子的摩擦，从而引起不同地点相同事情的发生，这一般出现在同卵双胞胎身上，因为其基因的相似性决定了其相同分子摩擦的几率较大。
4．梦与不实印象（untrue impressions）：梦是在无意识情况下产生的思想，其本质也是信息。我们平时会产生不实印象，看到某情景感觉以前似乎发生过，可是以前却并没有发生，其实这是因为脑内分子摩擦引起信息，而信息并没有将能量马上释放出来，而是暂时储存起来，当另一时刻又有同样的分子摩擦时，其能量被激活，双倍能量释放出来，其中一半能量使我们思想，另一半能量使我们产生印象，这便是不实印象的本质。
5．化学反应：一切化学反应的本质都是信息。几种分子摩擦引起特定信息，又引起其他分子摩擦，在摩擦中化学键断裂与形成，完成化学反应。
6．命运与灵魂：古人相信命运，可能是冥冥之中感到在另一空间中我们是早已被安排好的个体，于是出现了人类对灵魂、神的遐想。
五、信息论假说的意义
信息论假说将物质与思想相统一，它是唯物主义发展所必经的一步，它用唯物的观点解释了人类一直无法弄清的问题。它自身只是一个假说，需要人类长时间去探索与证明，它自身也存在缺陷，需要人类的不断发现。也许它本来就是个错误，但它是人类成长的见证，是人类伟大的精神财富。
用信息论假说的观点看问题，可以使人类认识到一个全新的世界，并有助于探索世界更深的本质。它给人类提供了一个丰富的经验，是人类跳出固有思想看问题的典范。总之，不管它是否正确，它都是人类的不朽之作。
书名：信息论
出版社：哈尔滨工程大学出版社
作者: 唐世伟刘贤梅
ISBN: 9787811332780
开本： 16
页数: 217
定价： 25.00元
本书共分七章，第一章为绪论，介绍信息的基本概念和定义，信息论的起源、发展和研究内容；第二章为信源与信源熵，介绍各种熵的概念、性质、定理等；第三章为无失真信源编码，介绍了信源的定长和变长编码定理、方法，以及几种实用的无失真信源编码；第四章为限失真信源编码，介绍了信息率失真函数的定义、性质、计算及语音、图像信号的预测编码；第五章为信道及信道容量，介绍了单符号离散信道、多符号离散信道和多用户信道的信道模型及信道容量的计算；第六章为信道编码，介绍了信道编码的基本概念、信道编码定理、线性分组码和循环码；第七章为网络信息安全及密码学，介绍了密码学的基本概念、各种加密算法及数字签名等技术。
书名： 信息论
作　者：傅祖芸
出版社：电子工业出版社
出版时间：2007年05月
ISBN: 9787121042737
开本：16开
定价： 38.00 元
《信息论:基础理论与应用》(第2版)系统地论述了香农信息论基本理论及某些应用问题，基本覆盖了信息论的各个方面的内容。内容包括：信息的定义和度量；各类离散信源和连续信源的信息熵；有记忆，无记忆，离散和连续信道的信道容量；香农信息论的三个基本定理：无失真数据压缩（即无失真信源编码）的实用编码算法与方法，以及信道纠错编码的基本内容和分析方法。《信息论：基础理论与应用》(第2版)最后还简要地介绍了信息论与热力学，光学，统计学，生物学，和医学等其他学科交叉结合的应用内容。
第1章 绪论
第3章 离散信道及其信道容量
第4章 波形信源和波形信道
第5章 无失真信源编码定理
第6章 有噪信道编码定理
第7章 保真度准则下的信源编码
第8章 无失真的信源编码
第9章 信道的纠错编码
第10章网络信息论
第11章 保密系统的基本信息理论
第12章 信息论与其他学科的关系和应用
附录
参考书目和文献
……
封面

书名：信息论基础
作者：田宝玉杨洁贺志强王晓湘
出版社：人民邮电出版社
ISBN：9787115177902
出版时间：2008年8月第1版
开本：16开
页数：275页
定价：29.8元
书名：信息论基础习题解答
作者：田宝玉杨洁贺志强 许文俊王晓湘
出版社：人民邮电出版社
ISBN：9787115224552
出版时间：2010年10月第1版
开本：16开
页数：242页
定价：29元
《信息论基础》是作者多年教学和科研实践的积累，是在吸收国内外优秀教材优点的基础上，进一步优化整合教学内容，并进行改进和补充而成的。全书共分为12章，内容包括：信息的基本概念、香农信息论研究的内容与进展，离散信息的度量，离散信源，连续信息与连续信源，无失真信源编码，离散信道及其容量，有噪信道编码，波形信道，信息率失真函数，有约束信道及其编码，网络信息论初步，信息理论方法与应用等。
《信息论基础习题解答》是本科生教材《信息论基础》配套的辅助教学资料，主要目的是为学生提供更多的信息论基本问题解题示范，开阔学生的解题思路，提高学生解决与信息论有关的基础性或综合性问题的能力，进一步提高信息论课程理论教学的质量。本书很多习题来自传统或经典的国内外教科书，同时还包含相当数量的通过一线教师多年的教学实践提炼并得到验证的典型题。本书与主教材结构相同，也对应包含12章。内容包括“知识要点”、“例题精解”、“习题解答”、“补充题解”4个部分。
第1章 绪论
第2章 离散信息的度量
第3章离散信源
第4章 连续信息与连续信源
第5章 无失真信源编码
第6章 离散信道及其容量
第7章 有噪信道编码
第8章 波形信道
第9章 信息率失真函数
第10章 有约束信道及其编码
第11章 网络信息论初步
第12章 信息理论方法及其应用
参考文献
……
信息论基础教程（第2版）
作　者：李梅，李亦农　编著




封面

出版 社：北京邮电大学出版社
出版时间：2008-10-1
字　数：310000
版 次：2
页 数：217
印刷时间：2008-10-1
开 本：16开
印　 次：1
纸 张：胶版纸
I S B N ：9787563518685
包　装：平装
所属分类：图书&gt;&gt;工业技术&gt;&gt;电子通信&gt;&gt;通信&gt;&gt;通信理论
目录第1章 绪论
1．1 信息的概念
1．2 信息论的研究对象、目的和内容
第2章 信息的度量
2．1 自信息和互信息
2．1.1 自信息
2．1.2 互信息
2．2 平均自信息
2．2.1 平均自信息的概念
2．2.2熵函数的性质
2．2.3 联合熵与条件熵
2．3 平均互信息
2．3.1 平均互信息的概念
2．3.2 平均互信息的性质
2．3.3 数据处理定理
习题2
第3章 信源及信源熵
3．1 信源的分类及其数学模型
3．2 离散单符号信源
3．3 离散多符号信源
3．3.1 离散平稳无记忆信源
3．3.2 离散平稳有记忆信源
3．3.3马尔可夫信源
3．3.4 信源的相关性和剩余度
3．4 连续信源
3．4.1 连续信源的微分熵
3．4.2 连续信源的最大熵
3．4.3 连续信源的熵功率
习题3
第4章 信道及信道容量
4．1 信道的分类
4．2 离散单符号信道及其信道容量
4．2.1 离散单符号信道的数学模型
4．2.2 信道容量的概念
4．2.3 几种特殊信道的信道容量
4．2.4 离散对称信道的信道容量
4．2.5 一般离散信道的信道容量
4．2.6 信道容量定理
4.2.7 信道容量的迭代算法
4．3 离散多符号信道及其信道容量
4．4 组合信道及其信道容量
4．4.1 独立并联信道
4．4.2 级联信道
4．5 连续信道及其信道容量
4．5.1 连续随机变量的互信息
4．5.2高斯加性信道的信道容量
4．5.3 多维高斯加性信道的信道容量
4．6 波形信道及其信道容量
习题4
第5章 无失真信源编码
5．1 信源编码的相关概念
5．1.1 编码器
5．1.2 码的分类
5．2 定长码及定长信源编码定理
5．3 变长码及变长信源编码定理
5．3.1 Kraft不等式和McMman不等式
5．3.2 唯一可译码的判别准则
5．3.3 紧致码平均码长界限定理
5．3.4 无失真变长信源编码定理（香农第一定理）
5．4 变长码的编码方法
5．4.1 香农编码
5．4.2 香农一费诺一埃利斯编码
5．4.3 二元霍夫曼码
5．4.4 r元霍夫曼码
5．4.5 费诺码
5．5 实用的无失真信源编码方法
5．5.1 游程编码
5．5.2 算术编码
5．5.3 LZW编码
习题5
第6章 有噪信道编码
6．1 信道编码的相关概念
6．1.1 错误概率和译码规则
6．1.2 错误概率与编码方法
6．2 有噪信道编码定理
6．3 错误概率的上界
6．4 纠错编码
6．4.1 纠错码分类
6．4.2 纠错码的基本概念
6．4.3 线性分组码
6．4.4 卷积码
习题6
第7章 限失真信源编码
7．1 失真测度
7．1.1 失真函数
7．1.2 平均失真
7．2 信息率失真函数
7．2.1 D失真许可信道
7.2.2 信息率失真函数的定义
7．2.3 信息率失真函数R（D）的性质
7．3 限失真信源编码定理
7．4 信息率失真函数的计算
7．4.1 应用参量表示式计算R（D）
7．4.2 率失真函数的迭代算法
7．5 常用的限失真信源编码方法
7．5.1 量化编码
7．5.2 子带编码
7．5.3 预测编码
7．5.4 变换编码
习题7
附录A 数学预备知识
A.1概率论与随机过程
A.1.1 概率论的基本概念
A.1.2 随机变量及其分布
A.1.3 多维随机变量及其分布
A.1.4 随机变量的数字特征
A.1.5 随机过程
A.2 凸函数及Jensen不等式
A.3 信道容量定理引理
A.4 渐进等分割性和￡典型序列
附录B 上机作业
B.1 信道容量的迭代算法
B.2 唯一可译码判决准则
B.3 Shannon编码
B.4 Huffman编码
B.5 Fano编码
B.6 LZW编码
B.7 BSC模拟器
B.8 Hamming（7，4）编译码器
B.9通信系统仿真
参考文献
中文书名：信息论基础
英文书名：Elements of Information Theory
作者：Thomas M.Cover, Joy A, Thomas
译者：阮吉寿，张华
出版社：机械工业出版社
版次：第1版 (2008年1月1日)
开本：16开
页数：439
ISBN：9787111220404
本书是信息论领域中一本经典且简明易懂的教材。主要内容包括：熵、信源、信道容量、率失真、数据压缩与编码理论和复杂度理论等方面的介绍。本书还对网络信息论和假设检验等进行了介绍，并且以赛马模型为出发点，将对证券市场的研究纳入了信息论的框架，从新的视角给投资组合的研究带来了全新的投资理念和研究技巧。本书适合作为电子工程、统计学以及电信方面的高年级本科生和研究生的信息论基础教程教材，也可供研究人员和专业人士参考。
第1章 绪论与概览
第2章 熵、相对熵与互信息
第3章 渐近均分性
第4章 随机过程的熵率
第5章 数据压缩
第6章 博弈与数据压缩
第7章 信道容量
第8章 微分熵
第9章高斯信道
第10章 率失真理论
第11章 信息论与统计学
第12章 最大熵
第13章 通用信源编码
第14章科尔莫戈罗夫复杂度
第15章 网络信息论
第16章 信息论与投资组合理论
第17章 信息论中的不等式
参考文献
